{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDAN20 - Assignment #3\n",
    "### Extracting noun groups using machine learning techniques\n",
    "Initial code provided by Pierre Nugues (@pnugues/ilpp)\n",
    "Completed by Jonathan Moran (jo6155mo-s) & Alexis Cole (alexiscole99)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing a training and a test sets\n",
    "1. As annotated data and annotation scheme, you will use the data available from CoNLL 2000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import conll_reader\n",
    "\n",
    "column_names = ['form', 'pos', 'chunk']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Download both the training and test sets (the same as in the previous assignment) and decompress them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = '../../corpus/conll2000/train.txt'\n",
    "test_file = '../../corpus/conll2000/test.txt'\n",
    "\n",
    "train_corpus = conll_reader.read_sentences(train_file)\n",
    "train_corpus = conll_reader.split_rows(train_corpus, column_names)\n",
    "test_corpus = conll_reader.read_sentences(test_file)\n",
    "test_corpus = conll_reader.split_rows(test_corpus, column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'form': 'Chancellor', 'pos': 'NNP', 'chunk': 'O'},\n",
       " {'form': 'of', 'pos': 'IN', 'chunk': 'B-PP'},\n",
       " {'form': 'the', 'pos': 'DT', 'chunk': 'B-NP'},\n",
       " {'form': 'Exchequer', 'pos': 'NNP', 'chunk': 'I-NP'},\n",
       " {'form': 'Nigel', 'pos': 'NNP', 'chunk': 'B-NP'},\n",
       " {'form': 'Lawson', 'pos': 'NNP', 'chunk': 'I-NP'},\n",
       " {'form': \"'s\", 'pos': 'POS', 'chunk': 'B-NP'},\n",
       " {'form': 'restated', 'pos': 'VBN', 'chunk': 'I-NP'},\n",
       " {'form': 'commitment', 'pos': 'NN', 'chunk': 'I-NP'},\n",
       " {'form': 'to', 'pos': 'TO', 'chunk': 'B-PP'},\n",
       " {'form': 'a', 'pos': 'DT', 'chunk': 'B-NP'},\n",
       " {'form': 'firm', 'pos': 'NN', 'chunk': 'I-NP'},\n",
       " {'form': 'monetary', 'pos': 'JJ', 'chunk': 'I-NP'},\n",
       " {'form': 'policy', 'pos': 'NN', 'chunk': 'I-NP'},\n",
       " {'form': 'has', 'pos': 'VBZ', 'chunk': 'B-VP'},\n",
       " {'form': 'helped', 'pos': 'VBN', 'chunk': 'I-VP'},\n",
       " {'form': 'to', 'pos': 'TO', 'chunk': 'I-VP'},\n",
       " {'form': 'prevent', 'pos': 'VB', 'chunk': 'I-VP'},\n",
       " {'form': 'a', 'pos': 'DT', 'chunk': 'B-NP'},\n",
       " {'form': 'freefall', 'pos': 'NN', 'chunk': 'I-NP'},\n",
       " {'form': 'in', 'pos': 'IN', 'chunk': 'B-PP'},\n",
       " {'form': 'sterling', 'pos': 'NN', 'chunk': 'B-NP'},\n",
       " {'form': 'over', 'pos': 'IN', 'chunk': 'B-PP'},\n",
       " {'form': 'the', 'pos': 'DT', 'chunk': 'B-NP'},\n",
       " {'form': 'past', 'pos': 'JJ', 'chunk': 'I-NP'},\n",
       " {'form': 'week', 'pos': 'NN', 'chunk': 'I-NP'},\n",
       " {'form': '.', 'pos': '.', 'chunk': 'O'}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_corpus[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'form': 'Rockwell', 'pos': 'NNP', 'chunk': 'B-NP'},\n",
       " {'form': 'said', 'pos': 'VBD', 'chunk': 'B-VP'},\n",
       " {'form': 'the', 'pos': 'DT', 'chunk': 'B-NP'},\n",
       " {'form': 'agreement', 'pos': 'NN', 'chunk': 'I-NP'},\n",
       " {'form': 'calls', 'pos': 'VBZ', 'chunk': 'B-VP'},\n",
       " {'form': 'for', 'pos': 'IN', 'chunk': 'B-SBAR'},\n",
       " {'form': 'it', 'pos': 'PRP', 'chunk': 'B-NP'},\n",
       " {'form': 'to', 'pos': 'TO', 'chunk': 'B-VP'},\n",
       " {'form': 'supply', 'pos': 'VB', 'chunk': 'I-VP'},\n",
       " {'form': '200', 'pos': 'CD', 'chunk': 'B-NP'},\n",
       " {'form': 'additional', 'pos': 'JJ', 'chunk': 'I-NP'},\n",
       " {'form': 'so-called', 'pos': 'JJ', 'chunk': 'I-NP'},\n",
       " {'form': 'shipsets', 'pos': 'NNS', 'chunk': 'I-NP'},\n",
       " {'form': 'for', 'pos': 'IN', 'chunk': 'B-PP'},\n",
       " {'form': 'the', 'pos': 'DT', 'chunk': 'B-NP'},\n",
       " {'form': 'planes', 'pos': 'NNS', 'chunk': 'I-NP'},\n",
       " {'form': '.', 'pos': '.', 'chunk': 'O'}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_corpus[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Be sure that you have the scikit-learn package: Start it by typing import sklearn in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline\n",
    "\n",
    "Most statistical algorithms for language processing start with a so-called baseline. The baseline figure corresponds to the application of a minimal technique that is used to assess the difficulty of a task and for comparison with further programs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Read the baseline proposed by the organizers of the CoNLL 2000 shared task (In the Results Sect.). What do you think of it?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Implement this baseline program. You may either create a completely new program or start from an existing program that you will modify [Program folder ]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For each part of speech, select the most frequent chunk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_pos(corpus):\n",
    "    \"\"\"\n",
    "    Computes the part-of-speech distribution\n",
    "    in a CoNLL 2000 file\n",
    "    :param corpus:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    pos_cnt = {}\n",
    "    for sentence in corpus:\n",
    "        for row in sentence:\n",
    "            if row['pos'] in pos_cnt:\n",
    "                pos_cnt[row['pos']] += 1\n",
    "            else:\n",
    "                pos_cnt[row['pos']] = 1\n",
    "\n",
    "    return pos_cnt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Complete the `train` function so that it computes the chunk distribution for each part of speech. You will use the `train` file to derive your distribution and you will store the results in a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(corpus):\n",
    "    \"\"\"\n",
    "    Computes the chunk distribution by pos\n",
    "    The result is stored in a dictionary\n",
    "    :param corpus: CoNLL tokens annotated with three-column tagset (POS, chunk tag, predicted chunk tag)\n",
    "    :return pos_chunk: dictionary containing the most-frequent pos-chunk associations\n",
    "    \"\"\"\n",
    "    pos_cnt = count_pos(corpus)\n",
    "\n",
    "    # We compute the chunk distribution by POS\n",
    "    chunk_dist = {key: {} for key in pos_cnt.keys()}\n",
    "\n",
    "    \"\"\"\n",
    "    Fill in code to compute the chunk distribution for each part of speech\n",
    "    Chunk distribution: num of pos-chunk associations \n",
    "    - case 1 (expected): chunk matches pos, incremement occurence count\n",
    "    - case 2 (initialisation): chunk matches pos, set count to 1\n",
    "    \"\"\"\n",
    "\n",
    "    for sentence in corpus:\n",
    "        for row in sentence:\n",
    "            # MODIFIED 5/10 -- @jonathanloganmoran:\n",
    "            chunk = row['chunk']\n",
    "            pos = row['pos']\n",
    "\n",
    "            if chunk in chunk_dist[pos]:\n",
    "                chunk_dist[pos][chunk] += 1\n",
    "            else:\n",
    "                chunk_dist[pos][chunk] = 1\n",
    "\n",
    "    print(chunk_dist['NNP'])\n",
    "                \n",
    "    \"\"\"\n",
    "    Fill in code so that for each part of speech, you select the most frequent chunk.\n",
    "    You will build a dictionary with key values:\n",
    "    pos_chunk[pos] = most frequent chunk for pos\n",
    "    \"\"\"\n",
    "    \n",
    "    # We determine the best association\n",
    "    pos_chunk = {}\n",
    "    \"\"\"\n",
    "    MODIFIED 5/10 -- @jonathanloganmoran:\n",
    "    - use lambda function to retrieve max POS\n",
    "    \"\"\"\n",
    "    for chunk in chunk_dist:\n",
    "        pos_chunk[chunk] = max(chunk_dist[chunk], key=lambda i: chunk_dist[chunk][i])\n",
    "    \n",
    "    return pos_chunk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In the example above, you will have (NN, I-NP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'B-NP': 8314, 'I-NP': 11470, 'O': 57, 'B-VP': 18, 'B-ADVP': 9, 'I-ADVP': 1, 'I-VP': 2, 'B-PRT': 1, 'B-ADJP': 8, 'B-INTJ': 2, 'I-ADJP': 2}\n",
      "Excerpt of training corpus for 'pos': 'NNP' tag:  I-NP\n"
     ]
    }
   ],
   "source": [
    "model = train(train_corpus)\n",
    "\n",
    "print(\"Excerpt of training corpus for 'pos': 'NNP' tag: \", model['NNP'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- You will store your results in an output file that has four columns. The three first columns will be the input columns from the test file: word, part of speech, and gold-standard chunk. You will append the predicted chunk as the 4th column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, corpus):\n",
    "    \"\"\"\n",
    "    Predicts the chunk from the part of speech\n",
    "    Adds a pchunk column\n",
    "    :param model: most-frequent pos-chunk associations\n",
    "    :param corpus: CoNLL annotated tokens + three-column tagset\n",
    "    :return: CoNLL dataset with predicted chunks\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    We add a predicted chunk column: pchunk\n",
    "    \"\"\"\n",
    "    for sentence in corpus:\n",
    "        for row in sentence:\n",
    "            row['pchunk'] = model[row['pos']]\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Your output file should look like the excerpt below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'form': 'Rockwell', 'pos': 'NNP', 'chunk': 'B-NP', 'pchunk': 'I-NP'}, {'form': 'said', 'pos': 'VBD', 'chunk': 'B-VP', 'pchunk': 'B-VP'}, {'form': 'the', 'pos': 'DT', 'chunk': 'B-NP', 'pchunk': 'B-NP'}, {'form': 'agreement', 'pos': 'NN', 'chunk': 'I-NP', 'pchunk': 'I-NP'}, {'form': 'calls', 'pos': 'VBZ', 'chunk': 'B-VP', 'pchunk': 'B-VP'}, {'form': 'for', 'pos': 'IN', 'chunk': 'B-SBAR', 'pchunk': 'B-PP'}, {'form': 'it', 'pos': 'PRP', 'chunk': 'B-NP', 'pchunk': 'B-NP'}, {'form': 'to', 'pos': 'TO', 'chunk': 'B-VP', 'pchunk': 'B-PP'}, {'form': 'supply', 'pos': 'VB', 'chunk': 'I-VP', 'pchunk': 'I-VP'}, {'form': '200', 'pos': 'CD', 'chunk': 'B-NP', 'pchunk': 'I-NP'}, {'form': 'additional', 'pos': 'JJ', 'chunk': 'I-NP', 'pchunk': 'I-NP'}, {'form': 'so-called', 'pos': 'JJ', 'chunk': 'I-NP', 'pchunk': 'I-NP'}, {'form': 'shipsets', 'pos': 'NNS', 'chunk': 'I-NP', 'pchunk': 'I-NP'}, {'form': 'for', 'pos': 'IN', 'chunk': 'B-PP', 'pchunk': 'B-PP'}, {'form': 'the', 'pos': 'DT', 'chunk': 'B-NP', 'pchunk': 'B-NP'}, {'form': 'planes', 'pos': 'NNS', 'chunk': 'I-NP', 'pchunk': 'I-NP'}, {'form': '.', 'pos': '.', 'chunk': 'O', 'pchunk': 'O'}]\n"
     ]
    }
   ],
   "source": [
    "predicted = predict(model, test_corpus)\n",
    "print(predicted[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Measure the performance of the system. Use the `conlleval.txt` evaluation program used by the CoNLL 2000 shared task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(predicted):\n",
    "    \"\"\"\n",
    "    Evaluates the predicted chunk accuracy\n",
    "    :param predicted: the pchunk-annotated dataset\n",
    "    :return: the percentage of correct chunk tags (classification accuracy)\n",
    "    \"\"\"\n",
    "    word_cnt = 0\n",
    "    correct = 0\n",
    "    for sentence in predicted:\n",
    "        for row in sentence:\n",
    "            word_cnt += 1\n",
    "            if row['chunk'] == row['pchunk']:\n",
    "                correct += 1\n",
    "    return correct / word_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.7729066846782194\n"
     ]
    }
   ],
   "source": [
    "accuracy = eval(predicted)\n",
    "print(\"Accuracy\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `conlleval.txt` is the official CoNLL Perl script. It expects the two last columns of the test set to be the manually assigned chunk (gold standard) and the predicted chunk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_out = open('out', 'w')\n",
    "# We write the word (form), part of speech (pos),\n",
    "# gold-standard chunk (chunk), and predicted chunk (pchunk)\n",
    "for sentence in predicted:\n",
    "    for row in sentence:\n",
    "        f_out.write(row['form'] + ' ' + row['pos'] + ' ' + row['chunk'] + ' ' + row['pchunk'] + '\\n')\n",
    "    f_out.write('\\n')\n",
    "f_out.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- where the `out` file contains both the gold and predicted chunk tags. `conlleval.txt` is a Perl script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed 47377 tokens with 23852 phrases; found: 26992 phrases; correct: 19592.\r\n",
      "accuracy:  77.29%; precision:  72.58%; recall:  82.14%; FB1:  77.07\r\n",
      "             ADJP: precision:   0.00%; recall:   0.00%; FB1:   0.00  0\r\n",
      "             ADVP: precision:  44.33%; recall:  77.71%; FB1:  56.46  1518\r\n",
      "            CONJP: precision:   0.00%; recall:   0.00%; FB1:   0.00  0\r\n",
      "             INTJ: precision:  50.00%; recall:  50.00%; FB1:  50.00  2\r\n",
      "              LST: precision:   0.00%; recall:   0.00%; FB1:   0.00  0\r\n",
      "               NP: precision:  79.87%; recall:  86.80%; FB1:  83.19  13500\r\n",
      "               PP: precision:  74.73%; recall:  97.07%; FB1:  84.45  6249\r\n",
      "              PRT: precision:  75.00%; recall:   8.49%; FB1:  15.25  12\r\n",
      "             SBAR: precision:   0.00%; recall:   0.00%; FB1:   0.00  0\r\n",
      "               VP: precision:  60.53%; recall:  74.22%; FB1:  66.68  5711\r\n"
     ]
    }
   ],
   "source": [
    "!perl conlleval.txt <out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Machine Learning\n",
    "\n",
    "\"In this exercise, you will apply and explore the `ml_chunker.py` program. You will start from the original program you downloaded and modify it so that you understand how to improve the performance of your chunker. You will not add new features to the feature vector.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\"\n",
    "CoNLL 2000 file reader\n",
    "\"\"\"\n",
    "__author__ = \"Pierre Nugues\"\n",
    "# MODIFIED -- @jonathanloganmoran\n",
    "\n",
    "def read_str(file):\n",
    "    \"\"\"\n",
    "    Creates a string of sentences from the corpus\n",
    "    :param file:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    f = str(open(file).read()).strip()\n",
    "    sentences = f.split('\\n\\n')\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# column_names = ['form', 'pos', 'chunk']\n",
    "train_file = '../../corpus/conll2000/train.txt'\n",
    "test_file = '../../corpus/conll2000/test.txt'\n",
    "\n",
    "train_sentences = read_str(train_file)\n",
    "# train_corpus = conll_reader.split_rows(train_corpus, column_names)\n",
    "test_sentences = read_str(test_file)\n",
    "# test_corpus = conll_reader.split_rows(test_corpus, column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_sent(sentence, w_size, feature_names):\n",
    "    \"\"\"\n",
    "    Extract the features from one sentence\n",
    "    returns X and y, where X is a list of dictionaries and\n",
    "    y is a list of symbols\n",
    "    :param sentence: string containing the CoNLL structure of a sentence\n",
    "    :param w_size:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    # We pad the sentence to extract the context window more easily\n",
    "    start = \"BOS BOS BOS\\n\"\n",
    "    end = \"\\nEOS EOS EOS\"\n",
    "    start *= w_size\n",
    "    end *= w_size\n",
    "    sentence = start + sentence\n",
    "    sentence += end\n",
    "\n",
    "    # Each sentence is a list of rows\n",
    "    sentence = sentence.splitlines()\n",
    "    padded_sentence = list()\n",
    "    for line in sentence:\n",
    "        line = line.split()\n",
    "        padded_sentence.append(line)\n",
    "    # print(padded_sentence)\n",
    "\n",
    "    # We extract the features and the classes\n",
    "    # X contains is a list of features, where each feature vector is a dictionary\n",
    "    # y is the list of classes\n",
    "    X = list()\n",
    "    y = list()\n",
    "    for i in range(len(padded_sentence) - 2 * w_size):\n",
    "        # x is a row of X\n",
    "        x = list()\n",
    "        # The words in lower case\n",
    "        for j in range(2 * w_size + 1):\n",
    "            x.append(padded_sentence[i + j][0].lower())\n",
    "        # The POS\n",
    "        for j in range(2 * w_size + 1):\n",
    "            x.append(padded_sentence[i + j][1])\n",
    "        # The chunks (Up to the word)\n",
    "        \"\"\"\n",
    "        for j in range(w_size):\n",
    "            feature_line.append(padded_sentence[i + j][2])\n",
    "        \"\"\"\n",
    "        # We represent the feature vector as a dictionary\n",
    "        X.append(dict(zip(feature_names, x)))\n",
    "        # The classes are stored in a list\n",
    "        y.append(padded_sentence[i + w_size][2])\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(sentences, w_size, feature_names):\n",
    "    \"\"\"\n",
    "    Builds X matrix and y vector\n",
    "    X is a list of dictionaries and y is a list\n",
    "    :param sentences:\n",
    "    :param w_size:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    X_l = []\n",
    "    y_l = []\n",
    "    for sentence in sentences:\n",
    "        X, y = extract_features_sent(sentence, w_size, feature_names)\n",
    "        X_l.extend(X)\n",
    "        y_l.extend(y)\n",
    "    return X_l, y_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting the features...\n"
     ]
    }
   ],
   "source": [
    "feature_names = ['word_n2', 'word_n1', 'word', 'word_p1', 'word_p2',\n",
    "                'pos_n2', 'pos_n1', 'pos', 'pos_p1', 'pos_p2']\n",
    "w_size = 2  # The size of the context window to the left and right of the word\n",
    "\n",
    "print(\"Extracting the features...\")\n",
    "X_dict, y = extract_features(train_sentences, w_size, feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding the features...\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "print(\"Encoding the features...\")\n",
    "# Vectorize the feature matrix and carry out a one-hot encoding\n",
    "vec = DictVectorizer(sparse=True)\n",
    "X = vec.fit_transform(X_dict)\n",
    "# The statement below will swallow a considerable memory\n",
    "# X = vec.fit_transform(X_dict).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "print(\"Training the model...\")\n",
    "classifier = linear_model.LogisticRegression(penalty='l2', dual=True, solver='liblinear')\n",
    "model = classifier.fit(X, y)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We apply the model to the test set\n",
    "# test_sentences = list(conll_reader.read_sentences(test_corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting the chunks in the test set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for classifier LogisticRegression(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
      "                   warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      B-ADJP       0.83      0.67      0.74       438\n",
      "      B-ADVP       0.81      0.81      0.81       866\n",
      "     B-CONJP       0.67      0.44      0.53         9\n",
      "      B-INTJ       1.00      0.50      0.67         2\n",
      "       B-LST       0.00      0.00      0.00         5\n",
      "        B-NP       0.96      0.96      0.96     12422\n",
      "        B-PP       0.96      0.98      0.97      4811\n",
      "       B-PRT       0.77      0.74      0.75       106\n",
      "      B-SBAR       0.89      0.84      0.87       535\n",
      "        B-VP       0.95      0.95      0.95      4658\n",
      "      I-ADJP       0.86      0.54      0.66       167\n",
      "      I-ADVP       0.63      0.48      0.55        89\n",
      "     I-CONJP       0.77      0.77      0.77        13\n",
      "       I-LST       0.00      0.00      0.00         2\n",
      "        I-NP       0.96      0.96      0.96     14376\n",
      "        I-PP       0.88      0.58      0.70        48\n",
      "      I-SBAR       0.07      0.25      0.11         4\n",
      "        I-VP       0.93      0.95      0.94      2646\n",
      "           O       0.95      0.96      0.96      6180\n",
      "\n",
      "    accuracy                           0.95     47377\n",
      "   macro avg       0.73      0.65      0.68     47377\n",
      "weighted avg       0.95      0.95      0.95     47377\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Here we carry out a chunk tag prediction and we report the per tag error\n",
    "# This is done for the whole corpus without regard for the sentence structure\n",
    "print(\"Predicting the chunks in the test set...\")\n",
    "X_test_dict, y_test = extract_features(test_sentences, w_size, feature_names)\n",
    "# Vectorize the test set and one-hot encoding\n",
    "X_test = vec.transform(X_test_dict)  # Possible to add: .toarray()\n",
    "y_test_predicted = classifier.predict(X_test)\n",
    "\n",
    "from sklearn import metrics\n",
    "print(\"Classification report for classifier %s:\\n%s\\n\" % (classifier, metrics.classification_report(y_test, y_test_predicted)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_new(test_sentences, feature_names, f_out):\n",
    "    for test_sentence in test_sentences:\n",
    "        X_test_dict, y_test = extract_features_sent(test_sentence, w_size, feature_names)\n",
    "        # Vectorize the test sentence and one hot encoding\n",
    "        X_test = vec.transform(X_test_dict)\n",
    "        # Predicts the chunks and returns numbers\n",
    "        y_test_predicted = classifier.predict(X_test)\n",
    "        # Appends the predicted chunks as a last column and saves the rows\n",
    "        rows = test_sentence.splitlines()\n",
    "        rows = [rows[i] + ' ' + y_test_predicted[i] for i in range(len(rows))]\n",
    "        for row in rows:\n",
    "            f_out.write(row + '\\n')\n",
    "        f_out.write('\\n')\n",
    "    f_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting the test set...\n"
     ]
    }
   ],
   "source": [
    "# Here we tag the test set and we save it.\n",
    "# This prediction is redundant with the piece of code above,\n",
    "# but we need to predict one sentence at a time to have the same\n",
    "# corpus structure\n",
    "print(\"Predicting the test set...\")\n",
    "f_out = open('out_v2', 'w')\n",
    "predict_new(test_sentences, feature_names, f_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CoNLL 2000 shared task (Kudoh and Matsumoto, 2000)\n",
    "The program that won the CoNLL 2000 shared task (Kudoh and Matsumoto, 2000) used a window of five words around the chunk tag to identify, `c_i` . They built a feature vector consisting of:\n",
    "\n",
    "- The values of the five words in this window: `w_i-2` , `w_i-1` , `w_i` , `w_i+1` , `w_i+2`\n",
    "- The values of the five parts of speech in this window: `t_i-2` , `t_i-1` , `t_i` , `t_i+1` , `t_i+2`\n",
    "- The values of the two previous chunk tags in the first part of the window: `c_i-2` , `c_i-1`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two last parameters are said to be dynamic because the program computes them at run-time. Kudoh and Matsumoto trained a classifier based on support vector machines. Read Kudoh and Matsumoto's paper and the Yamcha software site.\n",
    "\n",
    "##### 1. What is the feature vector that corresponds to the `ml_chunker.py` program? Is it the same Kudoh and Matsumoto used in their experiment?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. What is the performance of the chunker?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed 47377 tokens with 23852 phrases; found: 24251 phrases; correct: 22010.\r\n",
      "accuracy:  94.96%; precision:  90.76%; recall:  92.28%; FB1:  91.51\r\n",
      "             ADJP: precision:  74.22%; recall:  65.07%; FB1:  69.34  384\r\n",
      "             ADVP: precision:  78.45%; recall:  79.45%; FB1:  78.94  877\r\n",
      "            CONJP: precision:  44.44%; recall:  44.44%; FB1:  44.44  9\r\n",
      "             INTJ: precision: 100.00%; recall:  50.00%; FB1:  66.67  1\r\n",
      "              LST: precision:   0.00%; recall:   0.00%; FB1:   0.00  0\r\n",
      "               NP: precision:  90.31%; recall:  92.34%; FB1:  91.31  12701\r\n",
      "               PP: precision:  95.87%; recall:  97.86%; FB1:  96.85  4911\r\n",
      "              PRT: precision:  77.23%; recall:  73.58%; FB1:  75.36  101\r\n",
      "             SBAR: precision:  89.15%; recall:  84.49%; FB1:  86.76  507\r\n",
      "               VP: precision:  90.84%; recall:  92.83%; FB1:  91.82  4760\r\n"
     ]
    }
   ],
   "source": [
    "!perl conlleval.txt <out_v2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. Remove the lexical features (the words) from the feature vector and measure the performance. You should observe a decrease."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_sent_wordless(sentence, w_size, feature_names):\n",
    "    \"\"\"\n",
    "    Extract the features from one sentence\n",
    "    returns X and y, where X is a list of dictionaries and\n",
    "    y is a list of symbols\n",
    "    :param sentence: string containing the CoNLL structure of a sentence\n",
    "    :param w_size:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    # We pad the sentence to extract the context window more easily\n",
    "    start = \"BOS BOS BOS\\n\"\n",
    "    end = \"\\nEOS EOS EOS\"\n",
    "    start *= w_size\n",
    "    end *= w_size\n",
    "    sentence = start + sentence\n",
    "    sentence += end\n",
    "\n",
    "    # Each sentence is a list of rows\n",
    "    sentence = sentence.splitlines()\n",
    "    padded_sentence = list()\n",
    "    for line in sentence:\n",
    "        line = line.split()\n",
    "        padded_sentence.append(line)\n",
    "    # print(padded_sentence)\n",
    "\n",
    "    # We extract the features and the classes\n",
    "    # X contains is a list of features, where each feature vector is a dictionary\n",
    "    # y is the list of classes\n",
    "    X = list()\n",
    "    y = list()\n",
    "    for i in range(len(padded_sentence) - 2 * w_size):\n",
    "        # x is a row of X\n",
    "        x = list()\n",
    "        \n",
    "        # TASK 2.3 -- REMOVE THE LEXICAL FEATURES (WORDS)\n",
    "        \"\"\"\n",
    "        # The words in lower case\n",
    "        for j in range(2 * w_size + 1):\n",
    "            x.append(padded_sentence[i + j][0].lower())\n",
    "        \"\"\"\n",
    "        # The POS\n",
    "        for j in range(2 * w_size + 1):\n",
    "            x.append(padded_sentence[i + j][1])\n",
    "        # The chunks (Up to the word)\n",
    "        \"\"\"\n",
    "        for j in range(w_size):\n",
    "            feature_line.append(padded_sentence[i + j][2])\n",
    "        \"\"\"\n",
    "        # We represent the feature vector as a dictionary\n",
    "        X.append(dict(zip(feature_names, x)))\n",
    "        # The classes are stored in a list\n",
    "        y.append(padded_sentence[i + w_size][2])\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_wordless(sentences, w_size, feature_names):\n",
    "    \"\"\"\n",
    "    Builds X matrix and y vector\n",
    "    X is a list of dictionaries and y is a list\n",
    "    :param sentences:\n",
    "    :param w_size:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    X_l = []\n",
    "    y_l = []\n",
    "    for sentence in sentences:\n",
    "        X, y = extract_features_sent(sentence, w_size, feature_names)\n",
    "        X_l.extend(X)\n",
    "        y_l.extend(y)\n",
    "    return X_l, y_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_wordless(test_sentences, feature_names, f_out):\n",
    "    for test_sentence in test_sentences:\n",
    "        \n",
    "        # TASK 2.3 -- REMOVE THE LEXICAL FEATURES (WORDS)\n",
    "        X_test_dict, y_test = extract_features_sent_wordless(test_sentence, w_size, feature_names)\n",
    "        # Vectorize the test sentence and one hot encoding\n",
    "        X_test = vec.transform(X_test_dict)\n",
    "        # Predicts the chunks and returns numbers\n",
    "        y_test_predicted = classifier.predict(X_test)\n",
    "        # Appends the predicted chunks as a last column and saves the rows\n",
    "        rows = test_sentence.splitlines()\n",
    "        rows = [rows[i] + ' ' + y_test_predicted[i] for i in range(len(rows))]\n",
    "        for row in rows:\n",
    "            f_out.write(row + '\\n')\n",
    "        f_out.write('\\n')\n",
    "    f_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting the features...\n",
      "Encoding the features...\n",
      "Training the model...\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n",
      "Predicting the test set...\n"
     ]
    }
   ],
   "source": [
    "w_size = 2  # The size of the context window to the left and right of the word\n",
    "feature_names = ['word_n2', 'word_n1', 'word', 'word_p1', 'word_p2',\n",
    "                     'pos_n2', 'pos_n1', 'pos', 'pos_p1', 'pos_p2']\n",
    "\n",
    "print(\"Extracting the features...\")\n",
    "X_dict, y = extract_features_wordless(train_sentences, w_size, feature_names)\n",
    "\n",
    "print(\"Encoding the features...\")\n",
    "# Vectorize the feature matrix and carry out a one-hot encoding\n",
    "vec = DictVectorizer(sparse=True)\n",
    "X = vec.fit_transform(X_dict)\n",
    "# The statement below will swallow a considerable memory\n",
    "# X = vec.fit_transform(X_dict).toarray()\n",
    "\n",
    "#training_start_time = time.clock()\n",
    "print(\"Training the model...\")\n",
    "classifier = linear_model.LogisticRegression(penalty='l2', dual=True, solver='liblinear')\n",
    "model = classifier.fit(X, y)\n",
    "print(model)\n",
    "\n",
    "# Here we tag the test set and we save it.\n",
    "# This prediction is redundant with the piece of code above,\n",
    "# but we need to predict one sentence at a time to have the same\n",
    "# corpus structure\n",
    "print(\"Predicting the test set...\")\n",
    "f_out = open('out_wordless', 'w')\n",
    "predict_wordless(test_sentences, feature_names, f_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed 47377 tokens with 23852 phrases; found: 37022 phrases; correct: 4545.\r\n",
      "accuracy:  41.82%; precision:  12.28%; recall:  19.06%; FB1:  14.93\r\n",
      "             ADJP: precision:   0.00%; recall:   0.00%; FB1:   0.00  0\r\n",
      "             ADVP: precision:   0.00%; recall:   0.00%; FB1:   0.00  0\r\n",
      "            CONJP: precision:   0.00%; recall:   0.00%; FB1:   0.00  0\r\n",
      "             INTJ: precision:   0.00%; recall:   0.00%; FB1:   0.00  0\r\n",
      "              LST: precision:   0.00%; recall:   0.00%; FB1:   0.00  0\r\n",
      "               NP: precision:  12.28%; recall:  36.59%; FB1:  18.38  37022\r\n",
      "               PP: precision:   0.00%; recall:   0.00%; FB1:   0.00  0\r\n",
      "              PRT: precision:   0.00%; recall:   0.00%; FB1:   0.00  0\r\n",
      "             SBAR: precision:   0.00%; recall:   0.00%; FB1:   0.00  0\r\n",
      "               VP: precision:   0.00%; recall:   0.00%; FB1:   0.00  0\r\n"
     ]
    }
   ],
   "source": [
    "!perl conlleval.txt <out_wordless"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4. a) What is the classifier used in the program?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the `ml_chunker.py` program, the logisitic regression classifier is used. The model is provided by the scikit `linear_model` package."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4. b) Try two other classifiers and measure their performance: decision trees, perceptron, support vector machines, etc.. Be aware that support vector machines take a long time to train: up to one hour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model...\n",
      "Perceptron(alpha=0.0001, class_weight=None, early_stopping=False, eta0=1.0,\n",
      "           fit_intercept=True, max_iter=1000, n_iter_no_change=5, n_jobs=None,\n",
      "           penalty=None, random_state=0, shuffle=True, tol=0.001,\n",
      "           validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "Predicting the test set...\n"
     ]
    }
   ],
   "source": [
    "# Perceptron linear classifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "print(\"Training the model...\")\n",
    "classifier = Perceptron()\n",
    "model = classifier.fit(X, y)\n",
    "print(model)\n",
    "\n",
    "# Here we tag the test set and we save it.\n",
    "# This prediction is redundant with the piece of code above,\n",
    "# but we need to predict one sentence at a time to have the same\n",
    "# corpus structure\n",
    "print(\"Predicting the test set...\")\n",
    "f_out = open('out_perceptron', 'w')\n",
    "predict_new(test_sentences, feature_names, f_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed 47377 tokens with 23852 phrases; found: 24900 phrases; correct: 21464.\r\n",
      "accuracy:  93.20%; precision:  86.20%; recall:  89.99%; FB1:  88.05\r\n",
      "             ADJP: precision:  63.73%; recall:  57.76%; FB1:  60.60  397\r\n",
      "             ADVP: precision:  72.29%; recall:  77.71%; FB1:  74.90  931\r\n",
      "            CONJP: precision:   8.70%; recall:  22.22%; FB1:  12.50  23\r\n",
      "             INTJ: precision:  12.50%; recall:  50.00%; FB1:  20.00  8\r\n",
      "              LST: precision:   0.00%; recall:   0.00%; FB1:   0.00  7\r\n",
      "               NP: precision:  86.90%; recall:  89.71%; FB1:  88.28  12824\r\n",
      "               PP: precision:  94.82%; recall:  97.11%; FB1:  95.95  4927\r\n",
      "              PRT: precision:  63.33%; recall:  71.70%; FB1:  67.26  120\r\n",
      "             SBAR: precision:  87.00%; recall:  77.57%; FB1:  82.02  477\r\n",
      "              UCP: precision:   0.00%; recall:   0.00%; FB1:   0.00  376\r\n",
      "               VP: precision:  87.90%; recall:  90.77%; FB1:  89.31  4810\r\n"
     ]
    }
   ],
   "source": [
    "!perl conlleval.txt <out_perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model...\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best')\n",
      "Predicting the test set...\n"
     ]
    }
   ],
   "source": [
    "# Decision trees classifier\n",
    "from sklearn import tree\n",
    "\n",
    "print(\"Training the model...\")\n",
    "classifier = tree.DecisionTreeClassifier()\n",
    "model = classifier.fit(X, y)\n",
    "print(model)\n",
    "\n",
    "# Here we tag the test set and we save it.\n",
    "# This prediction is redundant with the piece of code above,\n",
    "# but we need to predict one sentence at a time to have the same\n",
    "# corpus structure\n",
    "print(\"Predicting the test set...\")\n",
    "f_out = open('out_trees', 'w')\n",
    "predict_new(test_sentences, feature_names, f_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed 47377 tokens with 23852 phrases; found: 24385 phrases; correct: 21929.\r\n",
      "accuracy:  94.74%; precision:  89.93%; recall:  91.94%; FB1:  90.92\r\n",
      "             ADJP: precision:  63.38%; recall:  67.58%; FB1:  65.41  467\r\n",
      "             ADVP: precision:  77.62%; recall:  76.91%; FB1:  77.26  858\r\n",
      "            CONJP: precision:  36.36%; recall:  44.44%; FB1:  40.00  11\r\n",
      "             INTJ: precision: 100.00%; recall:  50.00%; FB1:  66.67  1\r\n",
      "              LST: precision:   0.00%; recall:   0.00%; FB1:   0.00  0\r\n",
      "               NP: precision:  89.62%; recall:  92.27%; FB1:  90.93  12789\r\n",
      "               PP: precision:  96.36%; recall:  97.26%; FB1:  96.80  4856\r\n",
      "              PRT: precision:  68.38%; recall:  75.47%; FB1:  71.75  117\r\n",
      "             SBAR: precision:  86.19%; recall:  82.80%; FB1:  84.46  514\r\n",
      "               VP: precision:  90.07%; recall:  92.27%; FB1:  91.16  4772\r\n"
     ]
    }
   ],
   "source": [
    "!perl conlleval.txt <out_trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improving the Chunker\n",
    "Implement one of these two options, the first one being easier.\n",
    "\n",
    "1. Complement the feature vector used in the previous section with the two dynamic features, c i-2 , c i-1 , and train a new model. You will need to modify the extract_features_sent and predict functions. In his experiments, your teacher obtained a F1 score of 92.65 with logistic regression and a lbfgs solver and automatic multiclass;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_sent_dynamic(sentence, w_size, feature_names):\n",
    "    \"\"\"\n",
    "    Extract the features from one sentence\n",
    "    returns X and y, where X is a list of dictionaries and\n",
    "    y is a list of symbols\n",
    "    :param sentence: string containing the CoNLL structure of a sentence\n",
    "    :param w_size:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    # We pad the sentence to extract the context window more easily\n",
    "    start = \"BOS BOS BOS\\n\"\n",
    "    end = \"\\nEOS EOS EOS\"\n",
    "    start *= w_size\n",
    "    end *= w_size\n",
    "    sentence = start + sentence\n",
    "    sentence += end\n",
    "\n",
    "    # Each sentence is a list of rows\n",
    "    sentence = sentence.splitlines()\n",
    "    padded_sentence = list()\n",
    "    for line in sentence:\n",
    "        line = line.split()\n",
    "        padded_sentence.append(line)\n",
    "    # print(padded_sentence)\n",
    "\n",
    "    # We extract the features and the classes\n",
    "    # X contains is a list of features, where each feature vector is a dictionary\n",
    "    # y is the list of classes\n",
    "    X = list()\n",
    "    y = list()\n",
    "    for i in range(len(padded_sentence) - 2 * w_size):\n",
    "        # x is a row of X\n",
    "        x = list()\n",
    "        # The words in lower case\n",
    "        for j in range(2 * w_size + 1):\n",
    "            x.append(padded_sentence[i + j][0].lower())\n",
    "        # The POS\n",
    "        for j in range(2 * w_size + 1):\n",
    "            x.append(padded_sentence[i + j][1])\n",
    "        # The chunks (Up to the word)\n",
    "        \n",
    "        # TASK 3 -- PREDICTION USING DYNAMIC FEATURES\n",
    "        for j in range(w_size):\n",
    "            #feature_line.append(padded_sentence[i + j][2])\n",
    "            x.append(padded_sentence[i + j][2])\n",
    "        # We represent the feature vector as a dictionary\n",
    "        X.append(dict(zip(feature_names, x)))\n",
    "        # The classes are stored in a list\n",
    "        y.append(padded_sentence[i + w_size][2])\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_dynamic(sentences, w_size, feature_names):\n",
    "    \"\"\"\n",
    "    Builds X matrix and y vector\n",
    "    X is a list of dictionaries and y is a list\n",
    "    :param sentences:\n",
    "    :param w_size:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    X_l = []\n",
    "    y_l = []\n",
    "    for sentence in sentences:\n",
    "        X, y = extract_features_sent_dynamic(sentence, w_size, feature_names)\n",
    "        X_l.extend(X)\n",
    "        y_l.extend(y)\n",
    "    return X_l, y_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_dynamic(test_sentences, feature_names, f_out):\n",
    "    for test_sentence in test_sentences:\n",
    "        X_test_dict, y_test = extract_features_sent_dynamic(test_sentence, w_size, feature_names)\n",
    "        \n",
    "        # TASK 3 -- USING DYNAMIC FEATURES\n",
    "        y_c1 = \"BOS\"        # assume c_i-2 = starting identifier\n",
    "        y_c2 = \"BOS\"        # assume c_i-1 = starting identifier\n",
    "        \n",
    "        y_test_predicted = []\n",
    "        for sent, x_dict in enumerate(X_test_dict):\n",
    "            # using previous tag predicitions (the dynamic features)\n",
    "            x_dict[\"c_i-1\"] = y_c1\n",
    "            x_dict[\"c_i-2\"] = y_c2\n",
    "        \n",
    "            # Vectorize the test sentence and one hot encoding\n",
    "            X_test_vectorized = vec.transform(x_dict)\n",
    "            # Predicts the chunks and returns numbers\n",
    "            # y_test_predicted = classifier.predict(X_test_vectorized)\n",
    "            y_test_predicted.append(classifier.predict(X_test_vectorized))\n",
    "            \n",
    "            y_c2 = y_c1\n",
    "            y_c1 = y_test_predicted[sent][0]\n",
    "            \n",
    "        # Appends the predicted chunks as a last column and saves the rows\n",
    "        rows = test_sentence.splitlines()\n",
    "        rows = [rows[j] + ' ' + str(y_test_predicted[j][0]) for j in range(len(rows))]\n",
    "        for row in rows:\n",
    "            f_out.write(row + '\\n')\n",
    "        f_out.write('\\n')\n",
    "    f_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting the features...\n",
      "Encoding the features...\n",
      "Training the model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n",
      "Predicting the test set...\n"
     ]
    }
   ],
   "source": [
    "feature_names = ['word_n2', 'word_n1', 'word', 'word_p1', 'word_p2',\n",
    "                'pos_n2', 'pos_n1', 'pos', 'pos_p1', 'pos_p2']\n",
    "\n",
    "print(\"Extracting the features...\")\n",
    "X_dict, y = extract_features_dynamic(train_sentences, w_size, feature_names)\n",
    "\n",
    "print(\"Encoding the features...\")\n",
    "# Vectorize the feature matrix and carry out a one-hot encoding\n",
    "vec = DictVectorizer(sparse=True)\n",
    "X = vec.fit_transform(X_dict)\n",
    "# The statement below will swallow a considerable memory\n",
    "# X = vec.fit_transform(X_dict).toarray()\n",
    "\n",
    "print(\"Training the model...\")\n",
    "classifier = linear_model.LogisticRegression(penalty='l2', dual=True, solver='liblinear')\n",
    "model = classifier.fit(X, y)\n",
    "print(model)\n",
    "\n",
    "# Here we tag the test set and we save it.\n",
    "# This prediction is redundant with the piece of code above,\n",
    "# but we need to predict one sentence at a time to have the same\n",
    "# corpus structure\n",
    "print(\"Predicting the test set...\")\n",
    "f_out = open('out_dynamic', 'w')\n",
    "predict_dynamic(test_sentences, feature_names, f_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed 47377 tokens with 23852 phrases; found: 24251 phrases; correct: 22010.\r\n",
      "accuracy:  94.96%; precision:  90.76%; recall:  92.28%; FB1:  91.51\r\n",
      "             ADJP: precision:  74.22%; recall:  65.07%; FB1:  69.34  384\r\n",
      "             ADVP: precision:  78.45%; recall:  79.45%; FB1:  78.94  877\r\n",
      "            CONJP: precision:  44.44%; recall:  44.44%; FB1:  44.44  9\r\n",
      "             INTJ: precision: 100.00%; recall:  50.00%; FB1:  66.67  1\r\n",
      "              LST: precision:   0.00%; recall:   0.00%; FB1:   0.00  0\r\n",
      "               NP: precision:  90.31%; recall:  92.34%; FB1:  91.31  12701\r\n",
      "               PP: precision:  95.87%; recall:  97.86%; FB1:  96.85  4911\r\n",
      "              PRT: precision:  77.23%; recall:  73.58%; FB1:  75.36  101\r\n",
      "             SBAR: precision:  89.15%; recall:  84.49%; FB1:  86.76  507\r\n",
      "               VP: precision:  90.84%; recall:  92.83%; FB1:  91.82  4760\r\n"
     ]
    }
   ],
   "source": [
    "!perl conlleval.txt <out_dynamic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
